{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df87c642",
   "metadata": {},
   "source": [
    "# Coding a NN from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b41d0",
   "metadata": {},
   "source": [
    "## 1. Import MNIST dataset from PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5880eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b55299",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.ToTensor()\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root='./data/', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d75800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor() \n",
      "\n",
      " Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data/\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(mnist_trainset,'\\n\\n', mnist_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ed58b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I just want the whole dataset in a np array, I do not want to use PyTorch for anything else than downloading MNIST\n",
    "\n",
    "batch_size_train = 60000\n",
    "batch_size_test = 10000\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "train_examples = enumerate(train_loader) #returns an iterable object that will spit the samples by batch\n",
    "test_examples = enumerate(test_loader)\n",
    "\n",
    "# Batch size is equal to the m examples in both sets (train and test), so we only need to iterate them one time\n",
    "# Both batch indexes = 0 for the same reason stated before\n",
    "train_batch_idx, (X_train_tensor, y_train_tensor) = next(train_examples)\n",
    "test_batch_idx, (X_test_tensor, y_test_tensor) = next(test_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d53be5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor.shape: torch.Size([60000, 1, 28, 28]), y_train_tensor.shape: torch.Size([60000])\n",
      "X_test_tensor.shape: torch.Size([10000, 1, 28, 28]), y_test.shape: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train_tensor.shape: {X_train_tensor.shape}, y_train_tensor.shape: {y_train_tensor.shape}')\n",
    "print(f'X_test_tensor.shape: {X_test_tensor.shape}, y_test.shape: {y_test_tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75c60bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Let's convert those tensors to np arrays only with rows and columns\n",
    "\n",
    "def tensor_to_vector(tensor):\n",
    "    vector_nd = np.array(tensor)\n",
    "    vector = vector_nd.reshape(len(tensor),-1)\n",
    "    return vector\n",
    "\n",
    "X_train = tensor_to_vector(X_train_tensor)\n",
    "X_test = tensor_to_vector(X_test_tensor)\n",
    "y_train = np.array(y_train_tensor)\n",
    "y_test = np.array(y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bab18fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (60000, 784), y_train.shape: (60000,)\n",
      "X_test.shape: (10000, 784), y_test.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train.shape: {X_train.shape}, y_train.shape: {y_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}, y_test.shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37143cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (784, 60000), y_train.shape: (60000,)\n",
      "X_test.shape: (784, 10000), y_test.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# We want examples by columns so let's transpose the Xs\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "\n",
    "print(f'X_train.shape: {X_train.shape}, y_train.shape: {y_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}, y_test.shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b01a91a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NN is going to have: Input Layer (784) - HL1(10) - HL2(10)\n",
    "# Let's initalize all our parameters\n",
    "def init_parameters():\n",
    "    W1 = np.random.randn(10, 784)\n",
    "    b1 = np.random.randn(10, 1)\n",
    "    W2 = np.random.randn(10, 10)\n",
    "    b2 = np.random.randn(10, 1)\n",
    "    return W1, b1, W2, b2\n",
    "    \n",
    "def ReLU(Z):\n",
    "    a = np.maximun(0,Z) #this will return Z if the value is positive, otherwise 0\n",
    "    \n",
    "def SoftMax(Z):\n",
    "    summation_of_exps = np.sum(np.exp(Z))\n",
    "    return np.exp(Z)/summation_of_exps\n",
    "\n",
    "def fw_prop(A0, W1, b1, W2, b2):\n",
    "    #A0 = X\n",
    "    Z1 = W1.dot(A0) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = SoftMax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def one_hot_encoding(y):\n",
    "    n_categories = y.max() + 1     # 0-9, 10 categories\n",
    "    one_hot_y = np.zeros((y.size, n_categories))\n",
    "    one_hot_y[np.arange(y.size), y] = 1\n",
    "    one_hot_y = one_hot_y.T # We want the examples to be arranged by columns\n",
    "    return one_hot_y\n",
    "\n",
    "def b_prop(A0, W1, b1, W2, b2, y):\n",
    "    one_hot_y = one_hot_encoding(y)\n",
    "    dZ2 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9771ee2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10, 60000)\n",
      "8\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Test of the One-Hot-Encoding Function\n",
    "print(y_train[11230])\n",
    "print(oh_y[:,11230])\n",
    "\n",
    "#works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e65b2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I need to calculate manually the back prop\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
