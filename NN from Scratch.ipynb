{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df87c642",
   "metadata": {},
   "source": [
    "# Coding a NN from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b41d0",
   "metadata": {},
   "source": [
    "## 1. Import MNIST dataset from PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5880eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from numba import jit, cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b55299",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.ToTensor()\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root='./data/', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d75800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor() \n",
      "\n",
      " Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data/\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(mnist_trainset,'\\n\\n', mnist_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ed58b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I just want the whole dataset in a np array, I do not want to use PyTorch for anything else than downloading MNIST\n",
    "\n",
    "batch_size_train = 60000\n",
    "batch_size_test = 10000\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "train_examples = enumerate(train_loader) #returns an iterable object that will spit the samples by batch\n",
    "test_examples = enumerate(test_loader)\n",
    "\n",
    "# Batch size is equal to the m examples in both sets (train and test), so we only need to iterate them one time\n",
    "# Both batch indexes = 0 for the same reason stated before\n",
    "train_batch_idx, (X_train_tensor, y_train_tensor) = next(train_examples)\n",
    "test_batch_idx, (X_test_tensor, y_test_tensor) = next(test_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d53be5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor.shape: torch.Size([60000, 1, 28, 28]), y_train_tensor.shape: torch.Size([60000])\n",
      "X_test_tensor.shape: torch.Size([10000, 1, 28, 28]), y_test.shape: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train_tensor.shape: {X_train_tensor.shape}, y_train_tensor.shape: {y_train_tensor.shape}')\n",
    "print(f'X_test_tensor.shape: {X_test_tensor.shape}, y_test.shape: {y_test_tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75c60bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Let's convert those tensors to np arrays only with rows and columns\n",
    "\n",
    "def tensor_to_vector(tensor):\n",
    "    vector_nd = np.array(tensor)\n",
    "    vector = vector_nd.reshape(len(tensor),-1)\n",
    "    return vector\n",
    "\n",
    "X_train = tensor_to_vector(X_train_tensor)\n",
    "X_test = tensor_to_vector(X_test_tensor)\n",
    "y_train = np.array(y_train_tensor)\n",
    "y_test = np.array(y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bab18fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (60000, 784), y_train.shape: (60000,)\n",
      "X_test.shape: (10000, 784), y_test.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train.shape: {X_train.shape}, y_train.shape: {y_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}, y_test.shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37143cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (784, 60000), y_train.shape: (60000,)\n",
      "X_test.shape: (784, 10000), y_test.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# We want examples by columns so let's transpose the Xs\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "\n",
    "print(f'X_train.shape: {X_train.shape}, y_train.shape: {y_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}, y_test.shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b01a91a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NN is going to have: Input Layer (784) - HL1(10) - HL2(10)\n",
    "# Let's initalize all our parameters\n",
    "def init_parameters():\n",
    "    W1 = np.random.randn(10, 784) \n",
    "    b1 = np.random.randn(10, 1)\n",
    "    W2 = np.random.randn(10, 10)\n",
    "    b2 = np.random.randn(10, 1)\n",
    "    return W1, b1, W2, b2\n",
    "    \n",
    "def ReLU(Z):\n",
    "    a = np.maximum(0,Z) #this will return Z if the value is positive, otherwise 0\n",
    "    return a\n",
    "\n",
    "def SoftMax(Z):\n",
    "    summation_of_exps = sum(np.exp(Z))\n",
    "    return np.exp(Z)/summation_of_exps\n",
    "\n",
    "\n",
    "def fw_prop(A0, W1, b1, W2, b2):\n",
    "    #A0 = X\n",
    "    Z1 = W1.dot(A0) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = SoftMax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def one_hot_encoding(y):\n",
    "    n_categories = y.max() + 1     # 0-9, 10 categories\n",
    "    one_hot_y = np.zeros((y.size, n_categories))\n",
    "    one_hot_y[np.arange(y.size), y] = 1\n",
    "    one_hot_y = one_hot_y.T # We want the examples to be arranged by columns\n",
    "    return one_hot_y\n",
    "\n",
    "def d_ReLU(Z):\n",
    "    return Z > 0\n",
    "\n",
    "\n",
    "def b_prop(A0, Z1, A1, W2, Z2, A2, y):\n",
    "    m = y.size\n",
    "    one_hot_y = one_hot_encoding(y)\n",
    "    \n",
    "    dZ2 = (A2-one_hot_y)\n",
    "    dW2 = 1/m * dZ2.dot(A1.T)\n",
    "    db2 = 1/m * np.sum(dZ2)\n",
    "    dZ1 = W2.T.dot(dZ2) * d_ReLU(Z1)\n",
    "    dW1 = 1/m * dZ1.dot(A0.T)\n",
    "    db1 = 1/m * np.sum(dZ1)\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "\n",
    "def update_W(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b2 = b2 - alpha * db2\n",
    "    return W1, b1, W2, b2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9771ee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(A2):\n",
    "    y_pred = np.argmax(A2,0)\n",
    "    return y_pred\n",
    "\n",
    "def accuracy(y_pred, y):\n",
    "    accuracy = np.sum(y_pred == y) / y.size * 100\n",
    "    return accuracy\n",
    "\n",
    "def grad_desc(A0, y, iterations, alpha):\n",
    "    # Initialize Parmeters\n",
    "    W1, b1, W2, b2 = init_parameters()\n",
    "    \n",
    "    # Train Loop\n",
    "    for i in range(iterations):\n",
    "        # Forward Propagation\n",
    "        Z1, A1, Z2, A2 = fw_prop(A0, W1, b1, W2, b2)\n",
    "        # Back Propagation\n",
    "        dW1, db1, dW2, db2 = b_prop(A0, Z1, A1, W2, Z2, A2, y)\n",
    "        # Update Parameters\n",
    "        W1, b1, W2, b2 = update_W(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        \n",
    "        if i%20== 0:\n",
    "            print(f'Iteration: {i}')\n",
    "            y_pred = pred(A2)\n",
    "            print(y_pred)\n",
    "            score = accuracy(y_pred,y)\n",
    "            print(f'Accuracy: {score}')\n",
    "            \n",
    "    return W1, b1, W2, b2\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e65b2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "[6 6 8 ... 0 8 8]\n",
      "Accuracy: 11.808333333333334\n",
      "Iteration: 20\n",
      "[3 3 5 ... 1 3 0]\n",
      "Accuracy: 19.18\n",
      "Iteration: 40\n",
      "[5 3 3 ... 1 5 0]\n",
      "Accuracy: 21.923333333333332\n",
      "Iteration: 60\n",
      "[5 3 3 ... 1 5 2]\n",
      "Accuracy: 19.878333333333334\n",
      "Iteration: 80\n",
      "[5 3 3 ... 1 5 2]\n",
      "Accuracy: 21.498333333333335\n",
      "Iteration: 100\n",
      "[3 3 3 ... 1 3 2]\n",
      "Accuracy: 22.89\n",
      "Iteration: 120\n",
      "[3 3 3 ... 1 3 2]\n",
      "Accuracy: 23.898333333333333\n",
      "Iteration: 140\n",
      "[3 3 3 ... 1 3 2]\n",
      "Accuracy: 25.001666666666665\n",
      "Iteration: 160\n",
      "[3 3 3 ... 1 3 2]\n",
      "Accuracy: 26.205000000000002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m W1, b1, W2, b2 \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_desc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36mb_prop\u001b[1;34m(A0, Z1, A1, W2, Z2, A2, y)\u001b[0m\n\u001b[0;32m     44\u001b[0m db2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mm \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(dZ2)\n\u001b[0;32m     45\u001b[0m dZ1 \u001b[38;5;241m=\u001b[39m W2\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mdot(dZ2) \u001b[38;5;241m*\u001b[39m d_ReLU(Z1)\n\u001b[1;32m---> 46\u001b[0m dW1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mm \u001b[38;5;241m*\u001b[39m \u001b[43mdZ1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m db1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mm \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(dZ1)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dW1, db1, dW2, db2\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = grad_desc(X_train, y_train, 1000, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b0bb6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
