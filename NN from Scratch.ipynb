{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df87c642",
   "metadata": {},
   "source": [
    "# Coding a NN from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b41d0",
   "metadata": {},
   "source": [
    "## 1. Import MNIST dataset from PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5880eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b55299",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.ToTensor()\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root='./data/', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d75800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor() \n",
      "\n",
      " Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data/\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(mnist_trainset,'\\n\\n', mnist_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ed58b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I just want the whole dataset in a np array, I do not want to use PyTorch for anything else than downloading MNIST\n",
    "\n",
    "batch_size_train = 60000\n",
    "batch_size_test = 10000\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "train_examples = enumerate(train_loader) #returns an iterable object that will spit the samples by batch\n",
    "test_examples = enumerate(test_loader)\n",
    "\n",
    "# Batch size is equal to the m examples in both sets (train and test), so we only need to iterate them one time\n",
    "# Both batch indexes = 0 for the same reason stated before\n",
    "train_batch_idx, (X_train_tensor, y_train_tensor) = next(train_examples)\n",
    "test_batch_idx, (X_test_tensor, y_test_tensor) = next(test_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d53be5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor.shape: torch.Size([60000, 1, 28, 28]), y_train_tensor.shape: torch.Size([60000])\n",
      "X_test_tensor.shape: torch.Size([10000, 1, 28, 28]), y_test.shape: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train_tensor.shape: {X_train_tensor.shape}, y_train_tensor.shape: {y_train_tensor.shape}')\n",
    "print(f'X_test_tensor.shape: {X_test_tensor.shape}, y_test.shape: {y_test_tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75c60bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Let's convert those tensors to np arrays only with rows and columns\n",
    "\n",
    "def tensor_to_vector(tensor):\n",
    "    vector_nd = np.array(tensor)\n",
    "    vector = vector_nd.reshape(len(tensor),-1)\n",
    "    return vector\n",
    "\n",
    "X_train = tensor_to_vector(X_train_tensor)\n",
    "X_test = tensor_to_vector(X_test_tensor)\n",
    "y_train = np.array(y_train_tensor)\n",
    "y_test = np.array(y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12ef3935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (60000, 784), y_train.shape: (60000,)\n",
      "X_test.shape: (10000, 784), y_test.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train.shape: {X_train.shape}, y_train.shape: {y_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}, y_test.shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37143cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (784, 60000), y_train.shape: (60000,)\n",
      "X_test.shape: (784, 10000), y_test.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# We want examples by columns so let's transpose the Xs\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "\n",
    "print(f'X_train.shape: {X_train.shape}, y_train.shape: {y_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}, y_test.shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a91a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's initalize all our parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
